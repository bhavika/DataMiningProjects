/home/bhavika/anaconda2/bin/python /home/bhavika/PycharmProjects/Recommender/src/model6.py
This non-commercial license of GraphLab Create for academic use is assigned to btekwani@gmu.edu and will expire on November 03, 2017.
[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1478999178.log
Finished parsing file /home/bhavika/PycharmProjects/Recommender/src/movies_sf.csv
Parsing completed. Parsed 10195 lines in 0.581998 secs.
+---------+-----------+-----------+----------+--------+---------+---------+
| movieID | Adventure | Animation | Children | Comedy | Fantasy | Romance |
+---------+-----------+-----------+----------+--------+---------+---------+
|    1    |    True   |    True   |   True   |  True  |   True  |  False  |
|    2    |    True   |   False   |   True   | False  |   True  |  False  |
|    3    |   False   |   False   |  False   |  True  |  False  |   True  |
|    4    |   False   |   False   |  False   |  True  |  False  |   True  |
|    5    |   False   |   False   |  False   |  True  |  False  |  False  |
|    6    |   False   |   False   |  False   | False  |  False  |  False  |
|    7    |   False   |   False   |  False   |  True  |  False  |   True  |
|    8    |    True   |   False   |   True   | False  |  False  |  False  |
|    9    |   False   |   False   |  False   | False  |  False  |  False  |
|    10   |    True   |   False   |  False   | False  |  False  |  False  |
+---------+-----------+-----------+----------+--------+---------+---------+
+-------+--------+-------+----------+--------+---------+--------+-------+-------------+
| Drama | Action | Crime | Thriller | Horror | Mystery | Sci-Fi |  IMAX | Documentary |
+-------+--------+-------+----------+--------+---------+--------+-------+-------------+
| False | False  | False |  False   | False  |  False  | False  | False |    False    |
| False | False  | False |  False   | False  |  False  | False  | False |    False    |
| False | False  | False |  False   | False  |  False  | False  | False |    False    |
|  True | False  | False |  False   | False  |  False  | False  | False |    False    |
| False | False  | False |  False   | False  |  False  | False  | False |    False    |
| False |  True  |  True |   True   | False  |  False  | False  | False |    False    |
| False | False  | False |  False   | False  |  False  | False  | False |    False    |
| False | False  | False |  False   | False  |  False  | False  | False |    False    |
| False |  True  | False |  False   | False  |  False  | False  | False |    False    |
| False |  True  | False |   True   | False  |  False  | False  | False |    False    |
+-------+--------+-------+----------+--------+---------+--------+-------+-------------+
+-------+---------+-----------+---------+-----+
|  War  | Musical | Film-Noir | Western | ... |
+-------+---------+-----------+---------+-----+
| False |  False  |   False   |  False  | ... |
| False |  False  |   False   |  False  | ... |
| False |  False  |   False   |  False  | ... |
| False |  False  |   False   |  False  | ... |
| False |  False  |   False   |  False  | ... |
| False |  False  |   False   |  False  | ... |
| False |  False  |   False   |  False  | ... |
| False |  False  |   False   |  False  | ... |
| False |  False  |   False   |  False  | ... |
| False |  False  |   False   |  False  | ... |
+-------+---------+-----------+---------+-----+
[10195 rows x 62 columns]
Note: Only the head of the SFrame is printed.
You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.
Recsys training: model = factorization_recommender
Preparing data set.
    Data has 641699 observations with 2113 users and 10197 items.
    Data prepared in: 1.5748s
Training factorization_recommender for recommendations.
+--------------------------------+--------------------------------------------------+----------+
| Parameter                      | Description                                      | Value    |
+--------------------------------+--------------------------------------------------+----------+
| num_factors                    | Factor Dimension                                 | 64       |
| regularization                 | L2 Regularization on Factors                     | 1e-05    |
| solver                         | Solver used for training                         | adagrad  |
| linear_regularization          | L2 Regularization on Linear Coefficients         | 1e-08    |
| side_data_factorization        | Assign Factors for Side Data                     | True     |
| max_iterations                 | Maximum Number of Iterations                     | 100      |
+--------------------------------+--------------------------------------------------+----------+
  Optimizing model using SGD; tuning step size.
  Using 80212 / 641699 points for tuning the step size.
+---------+-------------------+------------------------------------------+
| Attempt | Initial Step Size | Estimated Objective Value                |
+---------+-------------------+------------------------------------------+
| 0       | 1                 | Not Viable                               |
| 1       | 0.25              | Not Viable                               |
| 2       | 0.0625            | 0.442531                                 |
| 3       | 0.03125           | 0.448167                                 |
| 4       | 0.015625          | 0.53909                                  |
| 5       | 0.0078125         | 0.584908                                 |
+---------+-------------------+------------------------------------------+
| Final   | 0.0625            | 0.442531                                 |
+---------+-------------------+------------------------------------------+
Starting Optimization.
+---------+--------------+-------------------+-----------------------+-------------+
| Iter.   | Elapsed Time | Approx. Objective | Approx. Training RMSE | Step Size   |
+---------+--------------+-------------------+-----------------------+-------------+
| Initial | 99us         | 1.00451           | 1.00225               |             |
+---------+--------------+-------------------+-----------------------+-------------+
| 1       | 16.84s       | 1.08383           | 1.00784               | 0.0625      |
| 2       | 41.28s       | 0.572882          | 0.708598              | 0.0625      |
| 3       | 1m 10s       | 0.540123          | 0.683562              | 0.0625      |
| 4       | 1m 45s       | 0.522886          | 0.669536              | 0.0625      |
| 5       | 2m 13s       | 0.510288          | 0.658895              | 0.0625      |
| 6       | 2m 43s       | 0.500294          | 0.650211              | 0.0625      |
| 7       | 3m 14s       | 0.491951          | 0.642783              | 0.0625      |
| 8       | 3m 36s       | 0.484542          | 0.636077              | 0.0625      |
| 9       | 3m 59s       | 0.478236          | 0.630229              | 0.0625      |
| 10      | 4m 25s       | 0.472322          | 0.624691              | 0.0625      |
| 11      | 4m 52s       | 0.467062          | 0.619667              | 0.0625      |
| 12      | 5m 17s       | 0.462121          | 0.614903              | 0.0625      |
| 13      | 5m 49s       | 0.457692          | 0.610547              | 0.0625      |
| 14      | 6m 30s       | 0.45324           | 0.606173              | 0.0625      |
| 15      | 7m 4s        | 0.449325          | 0.602242              | 0.0625      |
| 16      | 7m 41s       | 0.445701          | 0.598553              | 0.0625      |
| 17      | 8m 21s       | 0.442202          | 0.594965              | 0.0625      |
| 18      | 9m 3s        | 0.43865           | 0.591333              | 0.0625      |
| 19      | 9m 47s       | 0.435781          | 0.588274              | 0.0625      |
| 20      | 10m 33s      | 0.432709          | 0.585047              | 0.0625      |
| 21      | 11m 18s      | 0.429663          | 0.581842              | 0.0625      |
| 22      | 11m 54s      | 0.427066          | 0.579021              | 0.0625      |
| 23      | 12m 28s      | 0.424481          | 0.57621               | 0.0625      |
| 24      | 13m 1s       | 0.421871          | 0.573378              | 0.0625      |
| 25      | 13m 34s      | 0.419427          | 0.570694              | 0.0625      |
| 26      | 14m 7s       | 0.416951          | 0.567983              | 0.0625      |
| 27      | 14m 41s      | 0.414728          | 0.565489              | 0.0625      |
| 28      | 15m 14s      | 0.412739          | 0.563211              | 0.0625      |
| 29      | 15m 47s      | 0.410541          | 0.560746              | 0.0625      |
| 30      | 16m 35s      | 0.408655          | 0.558561              | 0.0625      |
| 31      | 17m 23s      | 0.406752          | 0.556363              | 0.0625      |
| 32      | 18m 2s       | 0.404898          | 0.554211              | 0.0625      |
| 33      | 18m 48s      | 0.402973          | 0.552003              | 0.0625      |
| 34      | 19m 30s      | 0.401151          | 0.549885              | 0.0625      |
| 35      | 20m 12s      | 0.399608          | 0.548021              | 0.0625      |
| 36      | 20m 54s      | 0.397852          | 0.545968              | 0.0625      |
| 37      | 21m 36s      | 0.396243          | 0.544051              | 0.0625      |
| 38      | 22m 14s      | 0.394817          | 0.542304              | 0.0625      |
| 39      | 23m 5s       | 0.393201          | 0.540381              | 0.0625      |
| 40      | 23m 49s      | 0.391773          | 0.538641              | 0.0625      |
| 41      | 24m 30s      | 0.390452          | 0.536999              | 0.0625      |
| 42      | 25m 10s      | 0.389065          | 0.535295              | 0.0625      |
| 43      | 25m 53s      | 0.387511          | 0.533439              | 0.0625      |
| 44      | 26m 38s      | 0.386253          | 0.53187               | 0.0625      |
| 45      | 27m 18s      | 0.385117          | 0.530407              | 0.0625      |
| 46      | 27m 54s      | 0.383824          | 0.528809              | 0.0625      |
| 47      | 28m 13s      | 0.382655          | 0.527331              | 0.0625      |
| 48      | 28m 31s      | 0.381468          | 0.525833              | 0.0625      |
| 49      | 28m 49s      | 0.380286          | 0.524341              | 0.0625      |
| 50      | 29m 7s       | 0.379236          | 0.522981              | 0.0625      |
| 51      | 29m 28s      | 0.378079          | 0.521524              | 0.0625      |
| 52      | 29m 46s      | 0.376978          | 0.520122              | 0.0625      |
| 53      | 30m 7s       | 0.376043          | 0.518883              | 0.0625      |
| 54      | 30m 26s      | 0.374937          | 0.517486              | 0.0625      |
| 55      | 30m 50s      | 0.373913          | 0.516161              | 0.0625      |
| 56      | 31m 11s      | 0.373053          | 0.515001              | 0.0625      |
| 57      | 31m 34s      | 0.372165          | 0.513818              | 0.0625      |
| 58      | 31m 55s      | 0.371245          | 0.512607              | 0.0625      |
| 59      | 32m 16s      | 0.370459          | 0.511525              | 0.0625      |
| 60      | 32m 37s      | 0.369553          | 0.510335              | 0.0625      |
| 61      | 32m 58s      | 0.368701          | 0.509203              | 0.0625      |
| 62      | 33m 19s      | 0.367872          | 0.50809               | 0.0625      |
| 63      | 33m 44s      | 0.367042          | 0.506978              | 0.0625      |
| 64      | 34m 25s      | 0.36626           | 0.505918              | 0.0625      |
| 65      | 35m 11s      | 0.365468          | 0.504845              | 0.0625      |
| 66      | 35m 51s      | 0.364798          | 0.5039                | 0.0625      |
| 67      | 36m 37s      | 0.36397           | 0.502803              | 0.0625      |
| 68      | 37m 17s      | 0.363222          | 0.501786              | 0.0625      |
| 69      | 38m 5s       | 0.362615          | 0.500912              | 0.0625      |
| 70      | 38m 47s      | 0.361777          | 0.49981               | 0.0625      |
| 71      | 39m 28s      | 0.361366          | 0.499139              | 0.0625      |
| 72      | 40m 13s      | 0.360475          | 0.497989              | 0.0625      |
| 73      | 40m 56s      | 0.359973          | 0.497226              | 0.0625      |
| 74      | 41m 36s      | 0.359314          | 0.49631               | 0.0625      |
| 75      | 42m 24s      | 0.35869           | 0.495433              | 0.0625      |
| 76      | 43m 21s      | 0.358083          | 0.49458               | 0.0625      |
| 77      | 44m 19s      | 0.357486          | 0.493736              | 0.0625      |
| 78      | 45m 21s      | 0.356885          | 0.492894              | 0.0625      |
| 79      | 46m 23s      | 0.356462          | 0.492229              | 0.0625      |
| 80      | 47m 19s      | 0.355908          | 0.491431              | 0.0625      |
| 81      | 48m 25s      | 0.355217          | 0.490503              | 0.0625      |
| 82      | 49m 28s      | 0.354691          | 0.489742              | 0.0625      |
| 83      | 50m 31s      | 0.354271          | 0.489092              | 0.0625      |
| 84      | 51m 40s      | 0.353569          | 0.488156              | 0.0625      |
| 85      | 52m 29s      | 0.353266          | 0.48763               | 0.0625      |
| 86      | 53m 19s      | 0.352658          | 0.486796              | 0.0625      |
| 87      | 54m 22s      | 0.352197          | 0.486106              | 0.0625      |
| 88      | 55m 28s      | 0.351577          | 0.485262              | 0.0625      |
| 89      | 56m 27s      | 0.351257          | 0.484726              | 0.0625      |
| 90      | 57m 35s      | 0.350795          | 0.484045              | 0.0625      |
| 91      | 58m 38s      | 0.350224          | 0.483256              | 0.0625      |
| 92      | 59m 43s      | 0.349934          | 0.482759              | 0.0625      |
| 93      | 1h 0m        | 0.349413          | 0.482019              | 0.0625      |
| 94      | 1h 1m        | 0.349019          | 0.481421              | 0.0625      |
| 95      | 1h 2m        | 0.348592          | 0.480787              | 0.0625      |
| 96      | 1h 3m        | 0.348192          | 0.48018               | 0.0625      |
| 97      | 1h 4m        | 0.347792          | 0.479577              | 0.0625      |
| 98      | 1h 4m        | 0.347483          | 0.479075              | 0.0625      |
| 99      | 1h 5m        | 0.347068          | 0.478455              | 0.0625      |
| 100     | 1h 5m        | 0.346637          | 0.477823              | 0.0625      |
+---------+--------------+-------------------+-----------------------+-------------+
Optimization Complete: Maximum number of passes through the data reached.
Computing final objective value and training RMSE.
       Final objective value: 0.341904
       Final training RMSE: 0.472844

Process finished with exit code 0
